{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45fe8071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted intent: Flights Info\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load saved model & tokenizer\n",
    "model_path = 'distilbert_airline'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# Example text\n",
    "text = \"Can you show me available flights to Paris in December?\"\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# Get label using id2label from model config\n",
    "predicted_label = model.config.id2label[predicted_class_id]\n",
    "\n",
    "print(\"Predicted intent:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "459892aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://a1afe4938436ea80b5.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a1afe4938436ea80b5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_path = \"distilbert_airline\"  # your saved model folder\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# Prediction function\n",
    "def predict_intent(text):\n",
    "    if not text.strip():\n",
    "        return \"Please enter some text.\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        predicted_id = torch.argmax(logits, dim=1).item()\n",
    "    return model.config.id2label[predicted_id]\n",
    "\n",
    "# Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=predict_intent,\n",
    "    inputs=gr.Textbox(lines=3, placeholder=\"Enter your query here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Airline Intent Classification\"\n",
    ")\n",
    "\n",
    "# Launch app with public link\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71f46c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://a65ec8dd2d872148b3.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a65ec8dd2d872148b3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dataset_path = \".gradio/flagged/dataset3.csv\"\n",
    "feedback_path = \".gradio/flagged/feedback.csv\"\n",
    "\n",
    "# Load dataset3.csv and prepare for dashboard\n",
    "def load_flagged():\n",
    "    if os.path.exists(dataset_path):\n",
    "        df = pd.read_csv(dataset_path, dtype=str)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=[\"text\",\"output\",\"timestamp\"])\n",
    "    # Add 'crted' column for admin input\n",
    "    if \"crted\" not in df.columns:\n",
    "        df[\"crted\"] = \"\"\n",
    "    # Ensure empty strings instead of NaN\n",
    "    df = df.fillna(\"\")\n",
    "    return df[[\"text\",\"output\",\"crted\",\"timestamp\"]]\n",
    "\n",
    "# Save only rows where crted is filled to feedback.csv\n",
    "def save_feedback(df):\n",
    "    # Select only rows where admin filled crted\n",
    "    df_to_save = df[df[\"crted\"].notna() & (df[\"crted\"] != \"\")]\n",
    "    if df_to_save.empty:\n",
    "        return df\n",
    "   \n",
    "    # Prepare feedback format: text, correct_label, timestamp\n",
    "    feedback_df = df_to_save[[\"text\",\"crted\",\"timestamp\"]].rename(\n",
    "        columns={\"crted\":\"correct_label\",\"timestamp\":\"timestamp\"}\n",
    "    )\n",
    "    \n",
    "    # Load existing feedback.csv if exists\n",
    "    if os.path.exists(feedback_path):\n",
    "        existing_feedback = pd.read_csv(feedback_path, dtype=str)\n",
    "        feedback_df = pd.concat([existing_feedback, feedback_df], ignore_index=True)\n",
    "        feedback_df = feedback_df.drop_duplicates(subset=\"text\", keep=\"last\")\n",
    "    \n",
    "    feedback_df.to_csv(feedback_path, index=False)\n",
    "    \n",
    "    # Remove saved rows from dataset3.csv\n",
    "    dataset_df = pd.read_csv(dataset_path, dtype=str)\n",
    "    dataset_df = dataset_df[~dataset_df[\"text\"].isin(df_to_save[\"text\"])]\n",
    "    dataset_df.to_csv(dataset_path, index=False)\n",
    "    \n",
    "    # Reload updated table\n",
    "    return load_flagged()\n",
    "# Admin UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Admin Panel: Correct Predicted Labels\")\n",
    "    \n",
    "    table = gr.Dataframe(\n",
    "        value=load_flagged(),\n",
    "        headers=[\"text\",\"output\",\"crted\",\"timestamp\"],\n",
    "        datatype=[\"str\",\"str\",\"str\",\"str\"],\n",
    "        interactive=True,\n",
    "        row_count=(1, \"dynamic\")  # allow deletion\n",
    "    )\n",
    "\n",
    "    save_btn = gr.Button(\"Save Corrections\")\n",
    "    save_btn.click(fn=save_feedback, inputs=[table], outputs=[table])\n",
    "\n",
    "    refresh_btn = gr.Button(\"Refresh Table\")\n",
    "    refresh_btn.click(fn=load_flagged, inputs=[], outputs=[table])\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "036b37e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping keras as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping tf-keras as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y tensorflow keras tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dbb70d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.48.2)\n",
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/soundarraj/Library/Python/3.12/lib/python/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/soundarraj/Library/Python/3.12/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/soundarraj/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio transformers datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f7201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
